# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11i99ErmiSaK8TbjfSYBTdD_Bmjohu3An
"""

from sklearn.model_selection import train_test_split
x_train, x_valid, y_train, y_valid = train_test_split(data, label,
                                                      test_size = 0.3)

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()

lr.fit(x_train, y_train)

y_pred = lr.predict(x_valid)
lr.predict_proba(x_valid)

from sklearn.metrics import accuracy_score
print('로지스틱 회귀, 정확도 : {:.2f}%'.format(accuracy_score(y_valid, y_pred)*100))
print('로지스틱 회귀, 계수(w) : {}, 절편(b) : {}').format(lr.coef_, lr.intercept_)

# SVM
# 경험적 위험 최소화(ERM) VS 구조적 위험 최소화(SRM)
# ERM : 훈련데이터에 대해 위험을 최소화
# SRM : 관찰하지 않은 데이터에 대해서도 위험을 최소화

from sklearn.svm import SVC
svc = SVC()

svc.fit(x_train, y_train)
y_pred = svc.predict(x_valid)
print('서포트 벡터 머신, 정확도 : {:.2f}%'.format(accuracy_score(y_valid, y_pred)*100))

# LightGBM
# XGBoost보다 속도가 더 빠르며 메모리 사용량은 적음
# XGBoost보다 더 나는 학습 성능
# 적은 데이터에서는 과적합 우려려

from lightgbm import LGBMClassifier
lgb = LGBMClassifier()
lgb.fit(x_train, y_train)
y_pred = lgb.predict(x_valid)
print('LightGBM, 정확도 : {:.2f}%'.format(accuracy_score(y_valid, y_pred)*100))

# 평가
# 1. 정확도(Accuracy)
# 2. 혼동 행렬(Confusion Matrix)
#    - 정밀도(Precision) : 모델이 1이라고 예측한 것 중 실제로 1인 것
#    - 재현율(Recall) : 실제로 1인 것 중 1이라고 예측한 것(질병이 맞는데 질병이라 나옴)
#    - 오탐(False Alarm) : 실제로 0인것 중 1이라고 예측한 것(질병이 아닌데 질병이라 나옴)
#    - 정밀도와 재현율의 조화 평균(F1 Score)
# 3. ROC Curve, AUC
#    - 민감도와 특이도가 서로 어떤 관계를 가지며 변하는지를 2차원 평면상에 나타낸 것
#    - ROC Curve : 그려지는 곡선
#    - AUC(Area Under Curve) : ROC Curve의 면적이며, 1에 가까울 수록 좋음음

from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier()
clf.fit(x_train, y_train)
y_pred = clf.predict(x_valid)
print('Accuracy : {:.3f}%'.format(accuracy_score(y_valid, y_pred)))
print('Precision : {:.3f}%'.format(Precision_score(y_valid, y_pred)))
print('Recall : {:.3f}%'.format(recall_score(y_valid, y_pred)))
print('F1 Score : {:.3f}%'.format(f1_score(y_valid, y_pred)))
print('AUC : {:.3f}%'.format(roc_auc_score(y_valid, y_pred)))